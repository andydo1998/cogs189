{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.kaggle.com/birdy654/eeg-brainwave-dataset-feeling-emotions/notebooks?datasetId=93959&sortBy=voteCount"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th># mean_0_a</th>\n",
       "      <th>mean_1_a</th>\n",
       "      <th>mean_2_a</th>\n",
       "      <th>mean_3_a</th>\n",
       "      <th>mean_4_a</th>\n",
       "      <th>mean_d_0_a</th>\n",
       "      <th>mean_d_1_a</th>\n",
       "      <th>mean_d_2_a</th>\n",
       "      <th>mean_d_3_a</th>\n",
       "      <th>mean_d_4_a</th>\n",
       "      <th>...</th>\n",
       "      <th>fft_741_b</th>\n",
       "      <th>fft_742_b</th>\n",
       "      <th>fft_743_b</th>\n",
       "      <th>fft_744_b</th>\n",
       "      <th>fft_745_b</th>\n",
       "      <th>fft_746_b</th>\n",
       "      <th>fft_747_b</th>\n",
       "      <th>fft_748_b</th>\n",
       "      <th>fft_749_b</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>4.62</td>\n",
       "      <td>30.3</td>\n",
       "      <td>-356.0</td>\n",
       "      <td>15.6</td>\n",
       "      <td>26.3</td>\n",
       "      <td>1.070</td>\n",
       "      <td>0.411</td>\n",
       "      <td>-15.70</td>\n",
       "      <td>2.06</td>\n",
       "      <td>3.15</td>\n",
       "      <td>...</td>\n",
       "      <td>23.5</td>\n",
       "      <td>20.3</td>\n",
       "      <td>20.3</td>\n",
       "      <td>23.5</td>\n",
       "      <td>-215.0</td>\n",
       "      <td>280.00</td>\n",
       "      <td>-162.00</td>\n",
       "      <td>-162.00</td>\n",
       "      <td>280.00</td>\n",
       "      <td>NEGATIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>28.80</td>\n",
       "      <td>33.1</td>\n",
       "      <td>32.0</td>\n",
       "      <td>25.8</td>\n",
       "      <td>22.8</td>\n",
       "      <td>6.550</td>\n",
       "      <td>1.680</td>\n",
       "      <td>2.88</td>\n",
       "      <td>3.83</td>\n",
       "      <td>-4.82</td>\n",
       "      <td>...</td>\n",
       "      <td>-23.3</td>\n",
       "      <td>-21.8</td>\n",
       "      <td>-21.8</td>\n",
       "      <td>-23.3</td>\n",
       "      <td>182.0</td>\n",
       "      <td>2.57</td>\n",
       "      <td>-31.60</td>\n",
       "      <td>-31.60</td>\n",
       "      <td>2.57</td>\n",
       "      <td>NEUTRAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>8.90</td>\n",
       "      <td>29.4</td>\n",
       "      <td>-416.0</td>\n",
       "      <td>16.7</td>\n",
       "      <td>23.7</td>\n",
       "      <td>79.900</td>\n",
       "      <td>3.360</td>\n",
       "      <td>90.20</td>\n",
       "      <td>89.90</td>\n",
       "      <td>2.03</td>\n",
       "      <td>...</td>\n",
       "      <td>462.0</td>\n",
       "      <td>-233.0</td>\n",
       "      <td>-233.0</td>\n",
       "      <td>462.0</td>\n",
       "      <td>-267.0</td>\n",
       "      <td>281.00</td>\n",
       "      <td>-148.00</td>\n",
       "      <td>-148.00</td>\n",
       "      <td>281.00</td>\n",
       "      <td>POSITIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>14.90</td>\n",
       "      <td>31.6</td>\n",
       "      <td>-143.0</td>\n",
       "      <td>19.8</td>\n",
       "      <td>24.3</td>\n",
       "      <td>-0.584</td>\n",
       "      <td>-0.284</td>\n",
       "      <td>8.82</td>\n",
       "      <td>2.30</td>\n",
       "      <td>-1.97</td>\n",
       "      <td>...</td>\n",
       "      <td>299.0</td>\n",
       "      <td>-243.0</td>\n",
       "      <td>-243.0</td>\n",
       "      <td>299.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>-12.40</td>\n",
       "      <td>9.53</td>\n",
       "      <td>9.53</td>\n",
       "      <td>-12.40</td>\n",
       "      <td>POSITIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>28.30</td>\n",
       "      <td>31.3</td>\n",
       "      <td>45.2</td>\n",
       "      <td>27.3</td>\n",
       "      <td>24.5</td>\n",
       "      <td>34.800</td>\n",
       "      <td>-5.790</td>\n",
       "      <td>3.06</td>\n",
       "      <td>41.40</td>\n",
       "      <td>5.52</td>\n",
       "      <td>...</td>\n",
       "      <td>12.0</td>\n",
       "      <td>38.1</td>\n",
       "      <td>38.1</td>\n",
       "      <td>12.0</td>\n",
       "      <td>119.0</td>\n",
       "      <td>-17.60</td>\n",
       "      <td>23.90</td>\n",
       "      <td>23.90</td>\n",
       "      <td>-17.60</td>\n",
       "      <td>NEUTRAL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 2549 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   # mean_0_a  mean_1_a  mean_2_a  mean_3_a  mean_4_a  mean_d_0_a  mean_d_1_a  \\\n",
       "0        4.62      30.3    -356.0      15.6      26.3       1.070       0.411   \n",
       "1       28.80      33.1      32.0      25.8      22.8       6.550       1.680   \n",
       "2        8.90      29.4    -416.0      16.7      23.7      79.900       3.360   \n",
       "3       14.90      31.6    -143.0      19.8      24.3      -0.584      -0.284   \n",
       "4       28.30      31.3      45.2      27.3      24.5      34.800      -5.790   \n",
       "\n",
       "   mean_d_2_a  mean_d_3_a  mean_d_4_a  ...  fft_741_b  fft_742_b  fft_743_b  \\\n",
       "0      -15.70        2.06        3.15  ...       23.5       20.3       20.3   \n",
       "1        2.88        3.83       -4.82  ...      -23.3      -21.8      -21.8   \n",
       "2       90.20       89.90        2.03  ...      462.0     -233.0     -233.0   \n",
       "3        8.82        2.30       -1.97  ...      299.0     -243.0     -243.0   \n",
       "4        3.06       41.40        5.52  ...       12.0       38.1       38.1   \n",
       "\n",
       "   fft_744_b  fft_745_b  fft_746_b  fft_747_b  fft_748_b  fft_749_b     label  \n",
       "0       23.5     -215.0     280.00    -162.00    -162.00     280.00  NEGATIVE  \n",
       "1      -23.3      182.0       2.57     -31.60     -31.60       2.57   NEUTRAL  \n",
       "2      462.0     -267.0     281.00    -148.00    -148.00     281.00  POSITIVE  \n",
       "3      299.0      132.0     -12.40       9.53       9.53     -12.40  POSITIVE  \n",
       "4       12.0      119.0     -17.60      23.90      23.90     -17.60   NEUTRAL  \n",
       "\n",
       "[5 rows x 2549 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('emotions.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Source: https://www.researchgate.net/publication/329403546_Mental_Emotional_Sentiment_Classification_with_an_EEG-based_Brain-machine_Interface\n",
    "\n",
    "https://www.researchgate.net/publication/335173767_A_Deep_Evolutionary_Approach_to_Bioinspired_Classifier_Optimisation_for_Brain-Machine_Interaction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We must first filter the dataset to optimize our model. As we can see, there are 2549 columns that get measured in this dataset. However, the model we chose only tests the \"mean\" columns. We note that the features we are using are the first 5 column and the label we are predicting is the last column. We will only select the columns accordingly so when we create the models, it will not loop through every column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th># mean_0_a</th>\n",
       "      <th>mean_1_a</th>\n",
       "      <th>mean_2_a</th>\n",
       "      <th>mean_3_a</th>\n",
       "      <th>mean_4_a</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>4.620</td>\n",
       "      <td>30.3</td>\n",
       "      <td>-356.0</td>\n",
       "      <td>15.60</td>\n",
       "      <td>26.3</td>\n",
       "      <td>NEGATIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>28.800</td>\n",
       "      <td>33.1</td>\n",
       "      <td>32.0</td>\n",
       "      <td>25.80</td>\n",
       "      <td>22.8</td>\n",
       "      <td>NEUTRAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>8.900</td>\n",
       "      <td>29.4</td>\n",
       "      <td>-416.0</td>\n",
       "      <td>16.70</td>\n",
       "      <td>23.7</td>\n",
       "      <td>POSITIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>14.900</td>\n",
       "      <td>31.6</td>\n",
       "      <td>-143.0</td>\n",
       "      <td>19.80</td>\n",
       "      <td>24.3</td>\n",
       "      <td>POSITIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>28.300</td>\n",
       "      <td>31.3</td>\n",
       "      <td>45.2</td>\n",
       "      <td>27.30</td>\n",
       "      <td>24.5</td>\n",
       "      <td>NEUTRAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2127</td>\n",
       "      <td>32.400</td>\n",
       "      <td>32.2</td>\n",
       "      <td>32.2</td>\n",
       "      <td>30.80</td>\n",
       "      <td>23.4</td>\n",
       "      <td>NEUTRAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2128</td>\n",
       "      <td>16.300</td>\n",
       "      <td>31.3</td>\n",
       "      <td>-284.0</td>\n",
       "      <td>14.30</td>\n",
       "      <td>23.9</td>\n",
       "      <td>POSITIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2129</td>\n",
       "      <td>-0.547</td>\n",
       "      <td>28.3</td>\n",
       "      <td>-259.0</td>\n",
       "      <td>15.80</td>\n",
       "      <td>26.7</td>\n",
       "      <td>NEGATIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2130</td>\n",
       "      <td>16.800</td>\n",
       "      <td>19.9</td>\n",
       "      <td>-288.0</td>\n",
       "      <td>8.34</td>\n",
       "      <td>26.0</td>\n",
       "      <td>NEGATIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2131</td>\n",
       "      <td>27.000</td>\n",
       "      <td>32.0</td>\n",
       "      <td>31.8</td>\n",
       "      <td>25.00</td>\n",
       "      <td>28.9</td>\n",
       "      <td>NEUTRAL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2132 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      # mean_0_a  mean_1_a  mean_2_a  mean_3_a  mean_4_a     label\n",
       "0          4.620      30.3    -356.0     15.60      26.3  NEGATIVE\n",
       "1         28.800      33.1      32.0     25.80      22.8   NEUTRAL\n",
       "2          8.900      29.4    -416.0     16.70      23.7  POSITIVE\n",
       "3         14.900      31.6    -143.0     19.80      24.3  POSITIVE\n",
       "4         28.300      31.3      45.2     27.30      24.5   NEUTRAL\n",
       "...          ...       ...       ...       ...       ...       ...\n",
       "2127      32.400      32.2      32.2     30.80      23.4   NEUTRAL\n",
       "2128      16.300      31.3    -284.0     14.30      23.9  POSITIVE\n",
       "2129      -0.547      28.3    -259.0     15.80      26.7  NEGATIVE\n",
       "2130      16.800      19.9    -288.0      8.34      26.0  NEGATIVE\n",
       "2131      27.000      32.0      31.8     25.00      28.9   NEUTRAL\n",
       "\n",
       "[2132 rows x 6 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.iloc[:, list(range(5)) + [-1]] # selects first 5 columns and last\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by making sure the data is in an understandable format. First, we have to check if there are any missing values. This line below first checks if anything is null and returns true or false accordingly, then takes the sum of all true and false (true being 1, false being 0), and then checks if there exist any Trues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This proves that there exists no missing values. This is a very good thing for us because this means that we do not have to compensate for any missing data. Next, the 'label' column is what we will be trying to predict. Let's get the unique values and see how the distribution is for all of the unique values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['NEGATIVE', 'NEUTRAL', 'POSITIVE'], dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = df['label']\n",
    "unique_labels = np.unique(labels)\n",
    "unique_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(labels)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NEUTRAL     716\n",
       "POSITIVE    708\n",
       "NEGATIVE    708\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the labels we are trying to predict will be 'neutral', 'positive', or 'negative'. We also know that they are about equally distributed. For a logistic regression model, we will need to assign the strings into a corresponding value. In this case, negative will be 0, neutral will be 1, and positive will be 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'NEGATIVE': 0, 'NEUTRAL': 1, 'POSITIVE': 2}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_labels = {key: val for val, key in enumerate(unique_labels)}\n",
    "new_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this new mapping, we can now create a new column to map these values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th># mean_0_a</th>\n",
       "      <th>mean_1_a</th>\n",
       "      <th>mean_2_a</th>\n",
       "      <th>mean_3_a</th>\n",
       "      <th>mean_4_a</th>\n",
       "      <th>label</th>\n",
       "      <th>new_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>4.62</td>\n",
       "      <td>30.3</td>\n",
       "      <td>-356.0</td>\n",
       "      <td>15.6</td>\n",
       "      <td>26.3</td>\n",
       "      <td>NEGATIVE</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>28.80</td>\n",
       "      <td>33.1</td>\n",
       "      <td>32.0</td>\n",
       "      <td>25.8</td>\n",
       "      <td>22.8</td>\n",
       "      <td>NEUTRAL</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>8.90</td>\n",
       "      <td>29.4</td>\n",
       "      <td>-416.0</td>\n",
       "      <td>16.7</td>\n",
       "      <td>23.7</td>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>14.90</td>\n",
       "      <td>31.6</td>\n",
       "      <td>-143.0</td>\n",
       "      <td>19.8</td>\n",
       "      <td>24.3</td>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>28.30</td>\n",
       "      <td>31.3</td>\n",
       "      <td>45.2</td>\n",
       "      <td>27.3</td>\n",
       "      <td>24.5</td>\n",
       "      <td>NEUTRAL</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   # mean_0_a  mean_1_a  mean_2_a  mean_3_a  mean_4_a     label  new_label\n",
       "0        4.62      30.3    -356.0      15.6      26.3  NEGATIVE          0\n",
       "1       28.80      33.1      32.0      25.8      22.8   NEUTRAL          1\n",
       "2        8.90      29.4    -416.0      16.7      23.7  POSITIVE          2\n",
       "3       14.90      31.6    -143.0      19.8      24.3  POSITIVE          2\n",
       "4       28.30      31.3      45.2      27.3      24.5   NEUTRAL          1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['new_label'] = df['label'].map(new_labels)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 'new_label' column corresponds to the 'label' column. Now, we must create a train/test split. This training subset will be used to train our model, and our testing subset will be used to test the accuracy of our model. For our project, we will be using a 80/20 train test split, which is a very common machine learning split because it provides a substantial amount of training data, as well as a good amount of data to test on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(['label', 'new_label'], axis = 1)\n",
    "y = df['new_label']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size = .8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th># mean_0_a</th>\n",
       "      <th>mean_1_a</th>\n",
       "      <th>mean_2_a</th>\n",
       "      <th>mean_3_a</th>\n",
       "      <th>mean_4_a</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>795</td>\n",
       "      <td>29.40</td>\n",
       "      <td>32.3</td>\n",
       "      <td>31.80</td>\n",
       "      <td>28.600</td>\n",
       "      <td>22.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2083</td>\n",
       "      <td>14.30</td>\n",
       "      <td>30.5</td>\n",
       "      <td>-176.00</td>\n",
       "      <td>13.400</td>\n",
       "      <td>27.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>405</td>\n",
       "      <td>-3.52</td>\n",
       "      <td>25.1</td>\n",
       "      <td>4.27</td>\n",
       "      <td>-15.800</td>\n",
       "      <td>21.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>871</td>\n",
       "      <td>8.65</td>\n",
       "      <td>16.1</td>\n",
       "      <td>-303.00</td>\n",
       "      <td>0.494</td>\n",
       "      <td>27.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1763</td>\n",
       "      <td>-2.07</td>\n",
       "      <td>18.4</td>\n",
       "      <td>-499.00</td>\n",
       "      <td>-0.984</td>\n",
       "      <td>26.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      # mean_0_a  mean_1_a  mean_2_a  mean_3_a  mean_4_a\n",
       "795        29.40      32.3     31.80    28.600      22.4\n",
       "2083       14.30      30.5   -176.00    13.400      27.4\n",
       "405        -3.52      25.1      4.27   -15.800      21.0\n",
       "871         8.65      16.1   -303.00     0.494      27.1\n",
       "1763       -2.07      18.4   -499.00    -0.984      26.8"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "795     1\n",
       "2083    0\n",
       "405     2\n",
       "871     0\n",
       "1763    0\n",
       "Name: new_label, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a training/testing dataset, we can now proceed to train our model on the training the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating the models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because we are incorporating 5 different features, we will be cross-validating our models to make sure that we are not overfitting our model.\n",
    "\n",
    "With 5 features, we will create 5 models:\n",
    "\n",
    "$M1: \\theta_0$ + $\\theta_1$ * mean_0_a\n",
    "\n",
    "$M2: \\theta_0$ + $\\theta_1$ * mean_0_a + $\\theta_2$ * mean_1_a\n",
    "\n",
    "$M3: \\theta_0$ + $\\theta_1$ * mean_0_a + $\\theta_2$ * mean_1_a + $\\theta_3$ * mean_2_a\n",
    "\n",
    "$M4: \\theta_0$ + $\\theta_1$ * mean_0_a + $\\theta_2$ * mean_1_a + $\\theta_3$ * mean_2_a + $\\theta_4$ * mean_3_a\n",
    "\n",
    "$M5: \\theta_0$ + $\\theta_1$ * mean_0_a + $\\theta_2$ * mean_1_a + $\\theta_3$ * mean_2_a + $\\theta_4$ * mean_3_a + $\\theta_5$ * mean_4_a\n",
    "\n",
    "Our process will be the same for each model: \n",
    "1. Create our feature vector by creating a column of ones\n",
    "2. Convert the features into a list\n",
    "3. Appending them to create a training vector\n",
    "4. Train the model on it\n",
    "5. Get the accuracy of each model on the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one hot encodes the features, does step 1-3 from above\n",
    "def one_hot_encoding(features, data):\n",
    "    ones = np.ones(len(data))\n",
    "    feat = [] # used to hold all the features after converting to a list\n",
    "    \n",
    "    # converts series into a list and stores it into a list\n",
    "    for i in features:\n",
    "        x_feat = data[i].tolist()\n",
    "        feat.append(x_feat)\n",
    "    \n",
    "    X = np.vstack([ones, feat])\n",
    "    X = X.T\n",
    "    \n",
    "    return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.  , 29.4 ],\n",
       "       [ 1.  , 14.3 ],\n",
       "       [ 1.  , -3.52],\n",
       "       ...,\n",
       "       [ 1.  , 27.8 ],\n",
       "       [ 1.  , 19.9 ],\n",
       "       [ 1.  , 29.3 ]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MODEL 1\n",
    "X1 = one_hot_encoding(['# mean_0_a'], X_train)\n",
    "X1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "    kernel='linear', max_iter=-1, probability=False, random_state=None,\n",
       "    shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m1 = svm.SVC(kernel = 'linear', C = 1.0)\n",
    "m1.fit(X1, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 2, ..., 1, 0, 1])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m1_pred = m1.predict(X1)\n",
    "m1_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6868035190615835"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# testing accuracy on m1\n",
    "m1_acc = sum(m1_pred == y_train) / len(y_train)\n",
    "m1_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.  , 29.4 , 32.3 ],\n",
       "       [ 1.  , 14.3 , 30.5 ],\n",
       "       [ 1.  , -3.52, 25.1 ],\n",
       "       ...,\n",
       "       [ 1.  , 27.8 , 30.6 ],\n",
       "       [ 1.  , 19.9 , 24.9 ],\n",
       "       [ 1.  , 29.3 , 34.2 ]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MODEL 2\n",
    "X2 = one_hot_encoding(['# mean_0_a', 'mean_1_a'], X_train)\n",
    "X2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "    kernel='linear', max_iter=-1, probability=False, random_state=None,\n",
       "    shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m2 = svm.SVC(kernel = 'linear', C = 1.0)\n",
    "m2.fit(X2, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "    kernel='linear', max_iter=-1, probability=False, random_state=None,\n",
       "    shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m2_pred = m2.predict(X2)\n",
    "m2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6832844574780058"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# testing accuracy on m2\n",
    "m2_acc = sum(m2_pred == y_train) / len(y_train)\n",
    "m2_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   1.  ,   29.4 ,   32.3 ,   31.8 ],\n",
       "       [   1.  ,   14.3 ,   30.5 , -176.  ],\n",
       "       [   1.  ,   -3.52,   25.1 ,    4.27],\n",
       "       ...,\n",
       "       [   1.  ,   27.8 ,   30.6 ,   29.6 ],\n",
       "       [   1.  ,   19.9 ,   24.9 , -202.  ],\n",
       "       [   1.  ,   29.3 ,   34.2 ,   30.3 ]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MODEL 3\n",
    "X3 = one_hot_encoding(['# mean_0_a', 'mean_1_a', 'mean_2_a'], X_train)\n",
    "X3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "    kernel='linear', max_iter=-1, probability=False, random_state=None,\n",
       "    shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m3 = svm.SVC(kernel = 'linear', C = 1.0)\n",
    "m3.fit(X3, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 2, ..., 1, 0, 1])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m3_pred = m3.predict(X3)\n",
    "m3_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9079178885630499"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# testing accuracy on m3\n",
    "m3_acc = sum(m3_pred == y_train) / len(y_train)\n",
    "m3_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   1.  ,   29.4 ,   32.3 ,   31.8 ,   28.6 ],\n",
       "       [   1.  ,   14.3 ,   30.5 , -176.  ,   13.4 ],\n",
       "       [   1.  ,   -3.52,   25.1 ,    4.27,  -15.8 ],\n",
       "       ...,\n",
       "       [   1.  ,   27.8 ,   30.6 ,   29.6 ,   26.4 ],\n",
       "       [   1.  ,   19.9 ,   24.9 , -202.  ,   12.3 ],\n",
       "       [   1.  ,   29.3 ,   34.2 ,   30.3 ,   27.  ]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MODEL 4\n",
    "X4 = one_hot_encoding(['# mean_0_a', 'mean_1_a', 'mean_2_a', 'mean_3_a'], X_train)\n",
    "X4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "    kernel='linear', max_iter=-1, probability=False, random_state=None,\n",
       "    shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m4 = svm.SVC(kernel = 'linear', C = 1.0)\n",
    "m4.fit(X4, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "    kernel='linear', max_iter=-1, probability=False, random_state=None,\n",
       "    shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m4_pred = m4.predict(X4)\n",
    "m4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.910850439882698"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# testing accuracy on m4\n",
    "m4_acc = sum(m4_pred == y_train) / len(y_train)\n",
    "m4_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   1.  ,   29.4 ,   32.3 ,   31.8 ,   28.6 ,   22.4 ],\n",
       "       [   1.  ,   14.3 ,   30.5 , -176.  ,   13.4 ,   27.4 ],\n",
       "       [   1.  ,   -3.52,   25.1 ,    4.27,  -15.8 ,   21.  ],\n",
       "       ...,\n",
       "       [   1.  ,   27.8 ,   30.6 ,   29.6 ,   26.4 ,   23.6 ],\n",
       "       [   1.  ,   19.9 ,   24.9 , -202.  ,   12.3 ,   26.8 ],\n",
       "       [   1.  ,   29.3 ,   34.2 ,   30.3 ,   27.  ,   24.4 ]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MODEL 5\n",
    "X5 = one_hot_encoding(['# mean_0_a', 'mean_1_a', 'mean_2_a', 'mean_3_a', 'mean_4_a'], X_train)\n",
    "X5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "    kernel='linear', max_iter=-1, probability=False, random_state=None,\n",
       "    shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m5 = svm.SVC(kernel = 'linear', C = 1.0)\n",
    "m5.fit(X5, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 2, ..., 1, 0, 1])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m5_pred = m5.predict(X5)\n",
    "m5_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.910850439882698"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# testing accuracy on m5\n",
    "m5_acc = sum(m5_pred == y_train) / len(y_train)\n",
    "m5_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It appears that model 4 performs the best on the training dataset. This could be because model 5 uses too many features so it overfits the model. Based on our training model accuracy, we will proceed this project using model #4, which was $M4: \\theta_0$ + $\\theta_1$ * mean_0_a + $\\theta_2$ * mean_1_a + $\\theta_3$ * mean_2_a + $\\theta_4$ * mean_3_a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  1.  ,  27.7 ,  30.2 ,  32.7 ,  28.9 ],\n",
       "       [  1.  ,  19.  ,  31.6 , -90.8 ,  19.7 ],\n",
       "       [  1.  ,  28.8 ,  30.8 ,  25.5 ,  27.3 ],\n",
       "       ...,\n",
       "       [  1.  ,   9.98,  29.3 ,  65.5 ,  17.3 ],\n",
       "       [  1.  ,  33.3 ,  35.2 ,  24.1 ,  28.1 ],\n",
       "       [  1.  ,  29.6 ,  30.7 ,  35.7 ,  28.2 ]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# converting testing set into a feature vector for our m4\n",
    "x4 = one_hot_encoding(['# mean_0_a', 'mean_1_a', 'mean_2_a', 'mean_3_a'], X_test)\n",
    "x4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, 1, 2, 1, 1, 0, 0, 0, 2, 1, 1, 1, 0, 2, 2, 1, 0, 1, 0, 0,\n",
       "       2, 1, 0, 2, 2, 0, 0, 1, 2, 1, 2, 2, 2, 1, 2, 0, 0, 1, 1, 1, 0, 0,\n",
       "       1, 0, 0, 0, 0, 0, 1, 1, 2, 0, 2, 2, 1, 0, 0, 1, 0, 0, 2, 0, 0, 1,\n",
       "       0, 0, 0, 2, 1, 0, 0, 2, 2, 0, 1, 1, 0, 0, 2, 1, 1, 2, 1, 0, 2, 1,\n",
       "       1, 0, 2, 1, 1, 0, 0, 0, 1, 2, 0, 0, 1, 2, 2, 1, 0, 1, 2, 0, 2, 1,\n",
       "       2, 2, 0, 2, 1, 0, 2, 0, 1, 0, 1, 2, 2, 1, 2, 1, 2, 1, 0, 1, 1, 0,\n",
       "       1, 0, 0, 0, 1, 2, 2, 0, 0, 0, 1, 0, 1, 2, 2, 1, 2, 0, 1, 2, 0, 2,\n",
       "       1, 1, 0, 0, 1, 1, 1, 2, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 2, 2, 0, 1,\n",
       "       0, 0, 0, 1, 2, 2, 0, 0, 2, 0, 0, 2, 1, 2, 2, 1, 1, 1, 0, 0, 1, 1,\n",
       "       0, 1, 1, 1, 2, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 2, 0, 0, 2, 1, 1, 0,\n",
       "       1, 1, 2, 1, 1, 1, 2, 2, 2, 1, 0, 2, 0, 2, 1, 2, 1, 1, 2, 1, 1, 1,\n",
       "       2, 0, 1, 0, 2, 2, 2, 0, 1, 2, 0, 0, 0, 0, 0, 2, 1, 1, 2, 1, 0, 0,\n",
       "       1, 0, 1, 1, 0, 0, 0, 2, 0, 0, 1, 0, 0, 0, 2, 2, 1, 2, 1, 2, 0, 0,\n",
       "       0, 1, 0, 0, 2, 0, 0, 2, 1, 0, 2, 0, 1, 1, 2, 1, 0, 2, 1, 2, 1, 2,\n",
       "       1, 1, 2, 0, 0, 0, 2, 1, 1, 1, 2, 1, 2, 0, 0, 1, 1, 0, 2, 0, 0, 2,\n",
       "       1, 0, 2, 1, 0, 2, 2, 0, 1, 1, 1, 0, 2, 2, 0, 0, 2, 2, 0, 1, 1, 0,\n",
       "       0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 2, 0, 1, 2, 0, 0, 0, 2, 1, 0, 0,\n",
       "       1, 2, 0, 0, 2, 0, 0, 1, 0, 1, 0, 0, 1, 0, 2, 1, 2, 0, 1, 0, 2, 0,\n",
       "       1, 2, 1, 0, 1, 0, 1, 0, 1, 0, 2, 0, 0, 0, 0, 0, 2, 0, 1, 2, 0, 0,\n",
       "       2, 1, 2, 1, 1, 0, 2, 1, 1])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = m4.predict(x4)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9039812646370023"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# testing accuracy on testing set\n",
    "testing_acc = sum(pred == y_test) / len(y_test)\n",
    "testing_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our model predicted 87.8% correctly on the testing dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Keep code here, perform same tests on a fixed dataset (top 80% / bottom 20% split)\n",
    "2. Run the model that uses a random split multiple times\n",
    "3. Use t-test to test significance difference between models (fixed dataset vs. random)\n",
    "4. \"does the time really matter in this dataset\"\n",
    "5. Pick best model, run multiple times in a loop and make a histogram to perform t-test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import svm\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this project, we will be creating a model to predict the "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.kaggle.com/birdy654/eeg-brainwave-dataset-feeling-emotions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th># mean_0_a</th>\n",
       "      <th>mean_1_a</th>\n",
       "      <th>mean_2_a</th>\n",
       "      <th>mean_3_a</th>\n",
       "      <th>mean_4_a</th>\n",
       "      <th>mean_d_0_a</th>\n",
       "      <th>mean_d_1_a</th>\n",
       "      <th>mean_d_2_a</th>\n",
       "      <th>mean_d_3_a</th>\n",
       "      <th>mean_d_4_a</th>\n",
       "      <th>...</th>\n",
       "      <th>fft_741_b</th>\n",
       "      <th>fft_742_b</th>\n",
       "      <th>fft_743_b</th>\n",
       "      <th>fft_744_b</th>\n",
       "      <th>fft_745_b</th>\n",
       "      <th>fft_746_b</th>\n",
       "      <th>fft_747_b</th>\n",
       "      <th>fft_748_b</th>\n",
       "      <th>fft_749_b</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>4.62</td>\n",
       "      <td>30.3</td>\n",
       "      <td>-356.0</td>\n",
       "      <td>15.6</td>\n",
       "      <td>26.3</td>\n",
       "      <td>1.070</td>\n",
       "      <td>0.411</td>\n",
       "      <td>-15.70</td>\n",
       "      <td>2.06</td>\n",
       "      <td>3.15</td>\n",
       "      <td>...</td>\n",
       "      <td>23.5</td>\n",
       "      <td>20.3</td>\n",
       "      <td>20.3</td>\n",
       "      <td>23.5</td>\n",
       "      <td>-215.0</td>\n",
       "      <td>280.00</td>\n",
       "      <td>-162.00</td>\n",
       "      <td>-162.00</td>\n",
       "      <td>280.00</td>\n",
       "      <td>NEGATIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>28.80</td>\n",
       "      <td>33.1</td>\n",
       "      <td>32.0</td>\n",
       "      <td>25.8</td>\n",
       "      <td>22.8</td>\n",
       "      <td>6.550</td>\n",
       "      <td>1.680</td>\n",
       "      <td>2.88</td>\n",
       "      <td>3.83</td>\n",
       "      <td>-4.82</td>\n",
       "      <td>...</td>\n",
       "      <td>-23.3</td>\n",
       "      <td>-21.8</td>\n",
       "      <td>-21.8</td>\n",
       "      <td>-23.3</td>\n",
       "      <td>182.0</td>\n",
       "      <td>2.57</td>\n",
       "      <td>-31.60</td>\n",
       "      <td>-31.60</td>\n",
       "      <td>2.57</td>\n",
       "      <td>NEUTRAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>8.90</td>\n",
       "      <td>29.4</td>\n",
       "      <td>-416.0</td>\n",
       "      <td>16.7</td>\n",
       "      <td>23.7</td>\n",
       "      <td>79.900</td>\n",
       "      <td>3.360</td>\n",
       "      <td>90.20</td>\n",
       "      <td>89.90</td>\n",
       "      <td>2.03</td>\n",
       "      <td>...</td>\n",
       "      <td>462.0</td>\n",
       "      <td>-233.0</td>\n",
       "      <td>-233.0</td>\n",
       "      <td>462.0</td>\n",
       "      <td>-267.0</td>\n",
       "      <td>281.00</td>\n",
       "      <td>-148.00</td>\n",
       "      <td>-148.00</td>\n",
       "      <td>281.00</td>\n",
       "      <td>POSITIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>14.90</td>\n",
       "      <td>31.6</td>\n",
       "      <td>-143.0</td>\n",
       "      <td>19.8</td>\n",
       "      <td>24.3</td>\n",
       "      <td>-0.584</td>\n",
       "      <td>-0.284</td>\n",
       "      <td>8.82</td>\n",
       "      <td>2.30</td>\n",
       "      <td>-1.97</td>\n",
       "      <td>...</td>\n",
       "      <td>299.0</td>\n",
       "      <td>-243.0</td>\n",
       "      <td>-243.0</td>\n",
       "      <td>299.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>-12.40</td>\n",
       "      <td>9.53</td>\n",
       "      <td>9.53</td>\n",
       "      <td>-12.40</td>\n",
       "      <td>POSITIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>28.30</td>\n",
       "      <td>31.3</td>\n",
       "      <td>45.2</td>\n",
       "      <td>27.3</td>\n",
       "      <td>24.5</td>\n",
       "      <td>34.800</td>\n",
       "      <td>-5.790</td>\n",
       "      <td>3.06</td>\n",
       "      <td>41.40</td>\n",
       "      <td>5.52</td>\n",
       "      <td>...</td>\n",
       "      <td>12.0</td>\n",
       "      <td>38.1</td>\n",
       "      <td>38.1</td>\n",
       "      <td>12.0</td>\n",
       "      <td>119.0</td>\n",
       "      <td>-17.60</td>\n",
       "      <td>23.90</td>\n",
       "      <td>23.90</td>\n",
       "      <td>-17.60</td>\n",
       "      <td>NEUTRAL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 2549 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   # mean_0_a  mean_1_a  mean_2_a  mean_3_a  mean_4_a  mean_d_0_a  mean_d_1_a  \\\n",
       "0        4.62      30.3    -356.0      15.6      26.3       1.070       0.411   \n",
       "1       28.80      33.1      32.0      25.8      22.8       6.550       1.680   \n",
       "2        8.90      29.4    -416.0      16.7      23.7      79.900       3.360   \n",
       "3       14.90      31.6    -143.0      19.8      24.3      -0.584      -0.284   \n",
       "4       28.30      31.3      45.2      27.3      24.5      34.800      -5.790   \n",
       "\n",
       "   mean_d_2_a  mean_d_3_a  mean_d_4_a  ...  fft_741_b  fft_742_b  fft_743_b  \\\n",
       "0      -15.70        2.06        3.15  ...       23.5       20.3       20.3   \n",
       "1        2.88        3.83       -4.82  ...      -23.3      -21.8      -21.8   \n",
       "2       90.20       89.90        2.03  ...      462.0     -233.0     -233.0   \n",
       "3        8.82        2.30       -1.97  ...      299.0     -243.0     -243.0   \n",
       "4        3.06       41.40        5.52  ...       12.0       38.1       38.1   \n",
       "\n",
       "   fft_744_b  fft_745_b  fft_746_b  fft_747_b  fft_748_b  fft_749_b     label  \n",
       "0       23.5     -215.0     280.00    -162.00    -162.00     280.00  NEGATIVE  \n",
       "1      -23.3      182.0       2.57     -31.60     -31.60       2.57   NEUTRAL  \n",
       "2      462.0     -267.0     281.00    -148.00    -148.00     281.00  POSITIVE  \n",
       "3      299.0      132.0     -12.40       9.53       9.53     -12.40  POSITIVE  \n",
       "4       12.0      119.0     -17.60      23.90      23.90     -17.60   NEUTRAL  \n",
       "\n",
       "[5 rows x 2549 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('emotions.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Source: https://www.researchgate.net/publication/329403546_Mental_Emotional_Sentiment_Classification_with_an_EEG-based_Brain-machine_Interface\n",
    "\n",
    "https://www.researchgate.net/publication/335173767_A_Deep_Evolutionary_Approach_to_Bioinspired_Classifier_Optimisation_for_Brain-Machine_Interaction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We must first filter the dataset to fit our model. As we can see, there are 2549 columns that get measured in this dataset. However, the model we chose only tests the \"mean\" columns. Although the descriptions of the columns are not very clear because there is no metadata for it, we tried to email the creator of the dataset but we were unable to get a response back. Other people have also posted about this problem, but there appears to be no public reply. We note that the features we are using are the first 5 column and the label we are predicting is the last column. We will only select the columns accordingly so that the table is filtered to only the columns we need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th># mean_0_a</th>\n",
       "      <th>mean_1_a</th>\n",
       "      <th>mean_2_a</th>\n",
       "      <th>mean_3_a</th>\n",
       "      <th>mean_4_a</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>4.620</td>\n",
       "      <td>30.3</td>\n",
       "      <td>-356.0</td>\n",
       "      <td>15.60</td>\n",
       "      <td>26.3</td>\n",
       "      <td>NEGATIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>28.800</td>\n",
       "      <td>33.1</td>\n",
       "      <td>32.0</td>\n",
       "      <td>25.80</td>\n",
       "      <td>22.8</td>\n",
       "      <td>NEUTRAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>8.900</td>\n",
       "      <td>29.4</td>\n",
       "      <td>-416.0</td>\n",
       "      <td>16.70</td>\n",
       "      <td>23.7</td>\n",
       "      <td>POSITIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>14.900</td>\n",
       "      <td>31.6</td>\n",
       "      <td>-143.0</td>\n",
       "      <td>19.80</td>\n",
       "      <td>24.3</td>\n",
       "      <td>POSITIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>28.300</td>\n",
       "      <td>31.3</td>\n",
       "      <td>45.2</td>\n",
       "      <td>27.30</td>\n",
       "      <td>24.5</td>\n",
       "      <td>NEUTRAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2127</td>\n",
       "      <td>32.400</td>\n",
       "      <td>32.2</td>\n",
       "      <td>32.2</td>\n",
       "      <td>30.80</td>\n",
       "      <td>23.4</td>\n",
       "      <td>NEUTRAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2128</td>\n",
       "      <td>16.300</td>\n",
       "      <td>31.3</td>\n",
       "      <td>-284.0</td>\n",
       "      <td>14.30</td>\n",
       "      <td>23.9</td>\n",
       "      <td>POSITIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2129</td>\n",
       "      <td>-0.547</td>\n",
       "      <td>28.3</td>\n",
       "      <td>-259.0</td>\n",
       "      <td>15.80</td>\n",
       "      <td>26.7</td>\n",
       "      <td>NEGATIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2130</td>\n",
       "      <td>16.800</td>\n",
       "      <td>19.9</td>\n",
       "      <td>-288.0</td>\n",
       "      <td>8.34</td>\n",
       "      <td>26.0</td>\n",
       "      <td>NEGATIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2131</td>\n",
       "      <td>27.000</td>\n",
       "      <td>32.0</td>\n",
       "      <td>31.8</td>\n",
       "      <td>25.00</td>\n",
       "      <td>28.9</td>\n",
       "      <td>NEUTRAL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2132 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      # mean_0_a  mean_1_a  mean_2_a  mean_3_a  mean_4_a     label\n",
       "0          4.620      30.3    -356.0     15.60      26.3  NEGATIVE\n",
       "1         28.800      33.1      32.0     25.80      22.8   NEUTRAL\n",
       "2          8.900      29.4    -416.0     16.70      23.7  POSITIVE\n",
       "3         14.900      31.6    -143.0     19.80      24.3  POSITIVE\n",
       "4         28.300      31.3      45.2     27.30      24.5   NEUTRAL\n",
       "...          ...       ...       ...       ...       ...       ...\n",
       "2127      32.400      32.2      32.2     30.80      23.4   NEUTRAL\n",
       "2128      16.300      31.3    -284.0     14.30      23.9  POSITIVE\n",
       "2129      -0.547      28.3    -259.0     15.80      26.7  NEGATIVE\n",
       "2130      16.800      19.9    -288.0      8.34      26.0  NEGATIVE\n",
       "2131      27.000      32.0      31.8     25.00      28.9   NEUTRAL\n",
       "\n",
       "[2132 rows x 6 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.iloc[:, list(range(5)) + [-1]] # selects first 5 columns and last\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using this line of code, we now have a dataframe that consists of the columns we need."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by making sure the data is in an understandable format. First, we have to check if there are any missing values. This line below first checks if anything is null and returns true or false accordingly, then takes the sum of all true and false (true being 1, false being 0), and then checks if there exist any Trues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This proves that there exists no missing values. This is a very good thing for us because this means that we do not have to compensate for any missing data. Next, the 'label' column is what we will be trying to predict. Let's get the unique values and see how the distribution is for all of the unique values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['NEGATIVE', 'NEUTRAL', 'POSITIVE'], dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = df['label']\n",
    "unique_labels = np.unique(labels)\n",
    "unique_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(labels)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NEUTRAL     716\n",
       "NEGATIVE    708\n",
       "POSITIVE    708\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the labels we are trying to predict will be 'neutral', 'positive', or 'negative'. We also know that they are about equally distributed. For a logistic regression model, we will need to assign the strings into a corresponding value. In this case, negative will be 0, neutral will be 1, and positive will be 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'NEGATIVE': 0, 'NEUTRAL': 1, 'POSITIVE': 2}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_labels = {key: val for val, key in enumerate(unique_labels)}\n",
    "new_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this new mapping, we can now create a new column to map these values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th># mean_0_a</th>\n",
       "      <th>mean_1_a</th>\n",
       "      <th>mean_2_a</th>\n",
       "      <th>mean_3_a</th>\n",
       "      <th>mean_4_a</th>\n",
       "      <th>label</th>\n",
       "      <th>new_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>4.62</td>\n",
       "      <td>30.3</td>\n",
       "      <td>-356.0</td>\n",
       "      <td>15.6</td>\n",
       "      <td>26.3</td>\n",
       "      <td>NEGATIVE</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>28.80</td>\n",
       "      <td>33.1</td>\n",
       "      <td>32.0</td>\n",
       "      <td>25.8</td>\n",
       "      <td>22.8</td>\n",
       "      <td>NEUTRAL</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>8.90</td>\n",
       "      <td>29.4</td>\n",
       "      <td>-416.0</td>\n",
       "      <td>16.7</td>\n",
       "      <td>23.7</td>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>14.90</td>\n",
       "      <td>31.6</td>\n",
       "      <td>-143.0</td>\n",
       "      <td>19.8</td>\n",
       "      <td>24.3</td>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>28.30</td>\n",
       "      <td>31.3</td>\n",
       "      <td>45.2</td>\n",
       "      <td>27.3</td>\n",
       "      <td>24.5</td>\n",
       "      <td>NEUTRAL</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   # mean_0_a  mean_1_a  mean_2_a  mean_3_a  mean_4_a     label  new_label\n",
       "0        4.62      30.3    -356.0      15.6      26.3  NEGATIVE          0\n",
       "1       28.80      33.1      32.0      25.8      22.8   NEUTRAL          1\n",
       "2        8.90      29.4    -416.0      16.7      23.7  POSITIVE          2\n",
       "3       14.90      31.6    -143.0      19.8      24.3  POSITIVE          2\n",
       "4       28.30      31.3      45.2      27.3      24.5   NEUTRAL          1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['new_label'] = df['label'].map(new_labels)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 'new_label' column corresponds to the 'label' column. We will now create 2 training/testing set. The first training/testing split will be the first 80%/last 20% of the dataset. Because this dataset is sampled by time, the index may be dependent on each other. The next set will be a shuffled 80/20 split. We will perform a t-test at the end to see if there is a huge significance between the time taken for each sample. This training subset will be used to train our model, and our testing subset will be used to test the accuracy of our model. For our project, we will be using a 80/20 train test split, which is a very common machine learning split because it provides a substantial amount of training data, as well as a good amount of data to test on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(['label', 'new_label'], axis = 1)\n",
    "y = df['new_label']\n",
    "\n",
    "# where the 80% of the dataset lies\n",
    "index = int(len(df) * .8)\n",
    "\n",
    "# obtaining the set, ns = no shuffle\n",
    "X_ns_train, y_ns_train = X[:index], y[:index]\n",
    "X_ns_test, y_ns_test = X[index:], y[:index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th># mean_0_a</th>\n",
       "      <th>mean_1_a</th>\n",
       "      <th>mean_2_a</th>\n",
       "      <th>mean_3_a</th>\n",
       "      <th>mean_4_a</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>4.62</td>\n",
       "      <td>30.3</td>\n",
       "      <td>-356.0</td>\n",
       "      <td>15.6</td>\n",
       "      <td>26.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>28.80</td>\n",
       "      <td>33.1</td>\n",
       "      <td>32.0</td>\n",
       "      <td>25.8</td>\n",
       "      <td>22.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>8.90</td>\n",
       "      <td>29.4</td>\n",
       "      <td>-416.0</td>\n",
       "      <td>16.7</td>\n",
       "      <td>23.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>14.90</td>\n",
       "      <td>31.6</td>\n",
       "      <td>-143.0</td>\n",
       "      <td>19.8</td>\n",
       "      <td>24.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>28.30</td>\n",
       "      <td>31.3</td>\n",
       "      <td>45.2</td>\n",
       "      <td>27.3</td>\n",
       "      <td>24.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   # mean_0_a  mean_1_a  mean_2_a  mean_3_a  mean_4_a\n",
       "0        4.62      30.3    -356.0      15.6      26.3\n",
       "1       28.80      33.1      32.0      25.8      22.8\n",
       "2        8.90      29.4    -416.0      16.7      23.7\n",
       "3       14.90      31.6    -143.0      19.8      24.3\n",
       "4       28.30      31.3      45.2      27.3      24.5"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_ns_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    1\n",
       "2    2\n",
       "3    2\n",
       "4    1\n",
       "Name: new_label, dtype: int64"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_ns_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a training/testing dataset, we can now proceed to train our model on the training the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating the models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because we are incorporating 5 different features, we will be cross-validating our models to make sure that we are not overfitting our model.\n",
    "\n",
    "With 5 features, we will create 5 models:\n",
    "\n",
    "$M1: \\theta_0$ + $\\theta_1$ * mean_0_a\n",
    "\n",
    "$M2: \\theta_0$ + $\\theta_1$ * mean_0_a + $\\theta_2$ * mean_1_a\n",
    "\n",
    "$M3: \\theta_0$ + $\\theta_1$ * mean_0_a + $\\theta_2$ * mean_1_a + $\\theta_3$ * mean_2_a\n",
    "\n",
    "$M4: \\theta_0$ + $\\theta_1$ * mean_0_a + $\\theta_2$ * mean_1_a + $\\theta_3$ * mean_2_a + $\\theta_4$ * mean_3_a\n",
    "\n",
    "$M5: \\theta_0$ + $\\theta_1$ * mean_0_a + $\\theta_2$ * mean_1_a + $\\theta_3$ * mean_2_a + $\\theta_4$ * mean_3_a + $\\theta_5$ * mean_4_a\n",
    "\n",
    "Our process will be the same for each model: \n",
    "1. Create our feature vector by creating a column of ones\n",
    "2. Convert the features into a list\n",
    "3. Appending them to create a training vector\n",
    "4. Train the model on it\n",
    "5. Get the accuracy of each model on the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creates a training vector, does step 1-3 from above\n",
    "def training_vector(features, data):\n",
    "    # creating a column of ones\n",
    "    ones = np.ones(len(data))\n",
    "    feat = [] # used to hold all the features after converting to a list\n",
    "    \n",
    "    # converts series into a list and stores it into a list\n",
    "    for i in features:\n",
    "        x_feat = data[i].tolist()\n",
    "        feat.append(x_feat)\n",
    "    \n",
    "    X = np.vstack([ones, feat])\n",
    "    X = X.T\n",
    "    \n",
    "    return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will create the 5 models above and obtain the accuracy to see which model is performing the best."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.  ,  4.62],\n",
       "       [ 1.  , 28.8 ],\n",
       "       [ 1.  ,  8.9 ],\n",
       "       ...,\n",
       "       [ 1.  , 27.7 ],\n",
       "       [ 1.  , 12.1 ],\n",
       "       [ 1.  , 16.5 ]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MODEL 1\n",
    "X1 = training_vector(['# mean_0_a'], X_ns_train)\n",
    "X1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "    kernel='linear', max_iter=-1, probability=False, random_state=None,\n",
       "    shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m1 = svm.SVC(kernel = 'linear', C = 1.0)\n",
    "m1.fit(X1, y_ns_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 1, 0, ..., 1, 0, 0])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m1_pred = m1.predict(X1)\n",
    "m1_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6850439882697947"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# testing accuracy on m1\n",
    "m1_acc = sum(m1_pred == y_ns_train) / len(y_ns_train)\n",
    "m1_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.  ,  4.62, 30.3 ],\n",
       "       [ 1.  , 28.8 , 33.1 ],\n",
       "       [ 1.  ,  8.9 , 29.4 ],\n",
       "       ...,\n",
       "       [ 1.  , 27.7 , 32.6 ],\n",
       "       [ 1.  , 12.1 , 30.6 ],\n",
       "       [ 1.  , 16.5 , 31.6 ]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MODEL 2\n",
    "X2 = one_hot_encoding(['# mean_0_a', 'mean_1_a'], X_ns_train)\n",
    "X2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "    kernel='linear', max_iter=-1, probability=False, random_state=None,\n",
       "    shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m2 = svm.SVC(kernel = 'linear', C = 1.0)\n",
    "m2.fit(X2, y_ns_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "    kernel='linear', max_iter=-1, probability=False, random_state=None,\n",
       "    shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m2_pred = m2.predict(X2)\n",
    "m2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6821114369501466"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# testing accuracy on m2\n",
    "m2_acc = sum(m2_pred == y_ns_train) / len(y_ns_train)\n",
    "m2_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   1.  ,    4.62,   30.3 , -356.  ],\n",
       "       [   1.  ,   28.8 ,   33.1 ,   32.  ],\n",
       "       [   1.  ,    8.9 ,   29.4 , -416.  ],\n",
       "       ...,\n",
       "       [   1.  ,   27.7 ,   32.6 ,   31.2 ],\n",
       "       [   1.  ,   12.1 ,   30.6 , -227.  ],\n",
       "       [   1.  ,   16.5 ,   31.6 , -147.  ]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MODEL 3\n",
    "X3 = one_hot_encoding(['# mean_0_a', 'mean_1_a', 'mean_2_a'], X_ns_train)\n",
    "X3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "    kernel='linear', max_iter=-1, probability=False, random_state=None,\n",
       "    shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m3 = svm.SVC(kernel = 'linear', C = 1.0)\n",
    "m3.fit(X3, y_ns_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, ..., 1, 0, 0])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m3_pred = m3.predict(X3)\n",
    "m3_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9043988269794722"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# testing accuracy on m3\n",
    "m3_acc = sum(m3_pred == y_ns_train) / len(y_ns_train)\n",
    "m3_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   1.  ,    4.62,   30.3 , -356.  ,   15.6 ],\n",
       "       [   1.  ,   28.8 ,   33.1 ,   32.  ,   25.8 ],\n",
       "       [   1.  ,    8.9 ,   29.4 , -416.  ,   16.7 ],\n",
       "       ...,\n",
       "       [   1.  ,   27.7 ,   32.6 ,   31.2 ,   25.2 ],\n",
       "       [   1.  ,   12.1 ,   30.6 , -227.  ,   10.5 ],\n",
       "       [   1.  ,   16.5 ,   31.6 , -147.  ,   20.  ]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MODEL 4\n",
    "X4 = one_hot_encoding(['# mean_0_a', 'mean_1_a', 'mean_2_a', 'mean_3_a'], X_ns_train)\n",
    "X4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "    kernel='linear', max_iter=-1, probability=False, random_state=None,\n",
       "    shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m4 = svm.SVC(kernel = 'linear', C = 1.0)\n",
    "m4.fit(X4, y_ns_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, ..., 1, 0, 0])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m4_pred = m4.predict(X4)\n",
    "m4_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9008797653958944"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# testing accuracy on m4\n",
    "m4_acc = sum(m4_pred == y_ns_train) / len(y_ns_train)\n",
    "m4_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   1.  ,    4.62,   30.3 , -356.  ,   15.6 ,   26.3 ],\n",
       "       [   1.  ,   28.8 ,   33.1 ,   32.  ,   25.8 ,   22.8 ],\n",
       "       [   1.  ,    8.9 ,   29.4 , -416.  ,   16.7 ,   23.7 ],\n",
       "       ...,\n",
       "       [   1.  ,   27.7 ,   32.6 ,   31.2 ,   25.2 ,   24.1 ],\n",
       "       [   1.  ,   12.1 ,   30.6 , -227.  ,   10.5 ,   25.7 ],\n",
       "       [   1.  ,   16.5 ,   31.6 , -147.  ,   20.  ,   25.5 ]])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MODEL 5\n",
    "X5 = one_hot_encoding(['# mean_0_a', 'mean_1_a', 'mean_2_a', 'mean_3_a', 'mean_4_a'], X_ns_train)\n",
    "X5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "    kernel='linear', max_iter=-1, probability=False, random_state=None,\n",
       "    shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m5 = svm.SVC(kernel = 'linear', C = 1.0)\n",
    "m5.fit(X5, y_ns_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, ..., 1, 0, 0])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m5_pred = m5.predict(X5)\n",
    "m5_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9020527859237537"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# testing accuracy on m5\n",
    "m5_acc = sum(m5_pred == y_ns_train) / len(y_ns_train)\n",
    "m5_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best model was model  3  with accuracy  0.9008797653958944\n"
     ]
    }
   ],
   "source": [
    "# comparing all model accuracys\n",
    "model_acc = [m1_acc, m2_acc, m3_acc, m4_acc, m5_acc]\n",
    "best_model_acc = model_acc.index(max(model_acc)) + 1 # index starts at 0 so we add 1 to get the correct model\n",
    "print('The best model was model ', best_model_acc, ' with accuracy ', model_acc[best_model_acc])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It appears that model 3 performs the best on the training dataset with no shuffle. We would think that the model that uses the most features gives us a more accurate prediction, but it seems like using more features would overfit the model. Based on our training model accuracy, we will proceed this project using model #3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Significance in time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to test whether there is a significance in time, we will perform a t-test. To do this, we will do 100 runs of:\n",
    "\n",
    "1. Shuffle the dataset into a 80/20 split\n",
    "2. Using model #3, we obtain the accuracy of the prediction\n",
    "3. We store the prediction in a variable\n",
    "4. We then use a t-test to see if there is a statistical difference between the time taken for each sample by comparing it to $\\alpha = .05$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "itterations = 100\n",
    "predictions = []\n",
    "\n",
    "for _ in range(itterations):\n",
    "    # creating the shuffled split\n",
    "    X_shuffled_train, _, y_shuffled_train, _ = train_test_split(X, y, train_size = .8)\n",
    "    X1 = one_hot_encoding(['# mean_0_a', 'mean_1_a', 'mean_2_a'], X_shuffled_train)\n",
    "    pred = m3.predict(X1)\n",
    "    acc = sum(pred == y_shuffled_train) / len(y_shuffled_train)\n",
    "    predictions.append(acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "m3_acc would never change because the set is the same, so we can just reproduce this value 100 times to match the numbers of itterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# m3_acc would never change because the set is same, so we can just \n",
    "no_shuffle_value = [m3_acc] * itterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ttest_indResult(statistic=2.1259502633951324, pvalue=0.03474623100054999)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats.ttest_ind(predictions, no_shuffle_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The p-value is lower than $\\alpha = .05$ so we believe that there is no statistical difference between the time taken for each sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
